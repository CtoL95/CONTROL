{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8a9c8b34",
   "metadata": {},
   "source": [
    "## Recognizing words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3be3792",
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "import math\n",
    "import numpy as np\n",
    "import numpy.random as npr\n",
    "from numpy import array, dot\n",
    "from numpy import linalg as LA\n",
    "from numpy.linalg import inv\n",
    "\n",
    "import pandas as pd\n",
    "import pandas_datareader.data as web\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.mlab as mlab\n",
    "\n",
    "import statsmodels.api as sm\n",
    "\n",
    "\n",
    "from scipy import stats\n",
    "from scipy.stats import skew\n",
    "from scipy.stats import kurtosis\n",
    "from scipy.stats import norm\n",
    "from scipy.stats import laplace\n",
    "from scipy.stats import cauchy\n",
    "\n",
    "from datetime import datetime\n",
    "from datetime import date\n",
    "from datetime import timedelta\n",
    "\n",
    "\n",
    "from pylab import plt, mpl\n",
    "from dataclasses import dataclass\n",
    "from typing import Optional, Union\n",
    "\n",
    "import sklearn\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn import linear_model\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "import nltk\n",
    "#from nltk.book import *\n",
    "from nltk.corpus import gutenberg\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk import word_tokenize\n",
    "from nltk import sent_tokenize\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "from nltk.tokenize import WordPunctTokenizer\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.stem.lancaster import LancasterStemmer\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "tk = WordPunctTokenizer()\n",
    "\n",
    "#from random import randrange\n",
    "import random\n",
    "import numpy as np\n",
    "import pylab as pl\n",
    "import networkx as nx\n",
    "\n",
    "import pandas as pd\n",
    "import yfinance as yf\n",
    "import numpy as np\n",
    "from datetime import datetime, date, timedelta, timezone\n",
    "import pandas_ta as ta\n",
    "from scipy.stats import linregress\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63067549",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def recognize(x, typ = \"reg\"):\n",
    "    operations = ['**','*','/','+','-']\n",
    "    #\n",
    "    ul = 11 #1000\n",
    "    ll = 0 #0\n",
    "\n",
    "    #\n",
    "    ul2 = 4 #100\n",
    "    ll2 = 1 #1\n",
    "\n",
    "    res = np.zeros(len(x))\n",
    "    print(\"type is: \",typ)\n",
    "    LSEX = 10000\n",
    "    q = 0\n",
    "\n",
    "    if len(x) < 3:\n",
    "\n",
    "        print(\"The dataset is too small\")\n",
    "\n",
    "    if len(x) >= 3:\n",
    "\n",
    "        for i in range(ll,ul):\n",
    "\n",
    "            for j in range(ll2,ul2):\n",
    "                q = i - 1\n",
    "                if i == 0:\n",
    "                    p = \"res[i] = \"+\"x[i1]\"                       \n",
    "\n",
    "                elif i > 0:\n",
    "                    p = \"res[i] = \" + str(q / j)   \n",
    "\n",
    "                for opr1 in operations: \n",
    "\n",
    "                        for k in range(ll,ul):\n",
    "                            for l in range(ll2,ul2):\n",
    "\n",
    "                                if k == 0:\n",
    "                                    pat = p + str(opr1) +\"x[i2]\" \n",
    "                                    #print(pat)\n",
    "                                elif k > 0:\n",
    "                                    pat = p + str(opr1) + str(k / l)\n",
    "                                    #print(pat)\n",
    "\n",
    "\n",
    "                                for opr2 in operations: \n",
    "\n",
    "                                    for g in range(ll,ul):\n",
    "                                        for h in range(ll2,ul2):\n",
    "                                            if str(opr2) == '**':\n",
    "                                                break\n",
    "\n",
    "                                            if g == 0:\n",
    "                                                patt = pat + str(opr2) +\"x[i3]\" \n",
    "                                                #print(patt)\n",
    "                                            elif g > 0:\n",
    "                                                patt = pat + str(opr2) + str(g / h)\n",
    "                                                #print(patt)\n",
    "\n",
    "                                            LSE = 0\n",
    "\n",
    "                                            if typ == \"diff\":\n",
    "                                                res = np.zeros(len(x)-1)\n",
    "                                            elif typ == \"reg\":\n",
    "                                                res = np.zeros(len(x))\n",
    "\n",
    "\n",
    "                                            for inte in range(len(x)):\n",
    "\n",
    "                                                if typ == \"diff\":\n",
    "\n",
    "                                                    if inte == 0:\n",
    "                                                        continue\n",
    "\n",
    "                                                    elif inte >= 1:\n",
    "                                                        pattern = patt.replace(\"i1\",str(inte-1))\n",
    "                                                        pattern = pattern.replace(\"i2\",str(inte-2))\n",
    "                                                        pattern = pattern.replace(\"i3\",str(inte-3))\n",
    "                                                        pattern = pattern.replace(\"i\",str(inte-1))\n",
    "\n",
    "                                                    try:\n",
    "                                                        exec(pattern)\n",
    "                                                    except:\n",
    "                                                        exec(\"res[\"+str(inte-1)+\"] = 0\")\n",
    "\n",
    "                                                    if inte == 0:\n",
    "                                                        LSE = 0\n",
    "\n",
    "                                                    elif inte >= 1:\n",
    "                                                        LSE = LSE + (x[(inte)] - res[inte-1])**2\n",
    "\n",
    "                                                if typ == \"reg\":\n",
    "\n",
    "                                                    if patt == 'res[i] = x[i1]**x[i2]**x[i3]':\n",
    "                                                        patt = 'res[i] = x[i1]**x[i2]'\n",
    "                                                    pattern = patt.replace(\"x[i1]\",str(inte+1))\n",
    "                                                    pattern = pattern.replace(\"x[i2]\",str(inte+1))\n",
    "                                                    pattern = pattern.replace(\"x[i3]\",str(inte+1))\n",
    "                                                    pattern = pattern.replace(\"i\",str(inte))\n",
    "\n",
    "                                                    exec(pattern)\n",
    "                                                    LSE = LSE + (x[inte] - res[inte])**2\n",
    "\n",
    "                                            if LSE < LSEX:\n",
    "                                                LSEX = LSE\n",
    "                                                result = res.tolist()\n",
    "                                                patterne = patt\n",
    "\n",
    "    pattern = patterne\n",
    "    p = 0\n",
    "    q = 0\n",
    "    lst = []\n",
    "    lste = \"\"\n",
    "    for i in range(len(patterne)):\n",
    "\n",
    "        try:\n",
    "            if type(int(patterne[i])) == int and patterne[i-1] != \"i\":\n",
    "                lste = str(lste) + str(patterne[i])\n",
    "            if i == len(patterne)-1 and len(lste) >=1:\n",
    "                lst.append(lste)\n",
    "        except ValueError:\n",
    "            if patterne[i] == \".\":\n",
    "                lste = str(lste) + str(patterne[i])\n",
    "            elif len(lste) >= 1:\n",
    "                lst.append(lste)\n",
    "                lste = \"\"\n",
    "\n",
    "    for i in range(len(lst)):\n",
    "\n",
    "        if len(lst) > 1 and i == 0:\n",
    "            p = float(lst[i])\n",
    "            q = float(lst[i+1])\n",
    "        elif len(lst) == 1:\n",
    "            p = float(patterne[lst[i]])\n",
    "\n",
    "        for j in range(1,11):\n",
    "            p1 = (p + 1/4 - 1/j)\n",
    "\n",
    "            for k in range(1,11):\n",
    "\n",
    "                if q != 0:\n",
    "                    q1 = (q + 1/4 - 1/k)\n",
    "                    if q1 == 0:\n",
    "                        q1 = 0.01\n",
    "\n",
    "                LSE = 0\n",
    "                patted = patterne.replace(\"res\",\"rest\")\n",
    "\n",
    "                if typ == \"diff\":\n",
    "                    rest = np.zeros(len(x)-1)\n",
    "\n",
    "                elif typ == \"reg\":\n",
    "                    rest = np.zeros(len(x))           \n",
    "\n",
    "                for inte in range(len(x)):\n",
    "\n",
    "                    patted = patted.replace(str(p), str(p1))\n",
    "\n",
    "                    if q != 0:\n",
    "                        patted = patted.replace(str(q), str(q1))\n",
    "\n",
    "                    if typ == \"diff\":\n",
    "                        if inte == 0:\n",
    "                            continue\n",
    "\n",
    "                        elif inte >= 1:\n",
    "                            patte = patted.replace(\"i1\",str(inte-1))\n",
    "                            patte = patte.replace(\"i2\",str(inte-2))\n",
    "                            patte = patte.replace(\"i3\",str(inte-3))\n",
    "                            patte = patte.replace(\"i\",str(inte-1))\n",
    "\n",
    "                        exec(patte)\n",
    "\n",
    "                        if inte == 0:\n",
    "                            LSE = 0\n",
    "\n",
    "                        elif inte >= 1:\n",
    "                            LSE = LSE + (x[(inte)] - rest[inte-1])**2\n",
    "\n",
    "\n",
    "                    if typ == \"reg\":\n",
    "\n",
    "                        patte = patted.replace(\"x[i1]\",str(inte+1))\n",
    "                        patte = patte.replace(\"x[i2]\",str(inte+1))\n",
    "                        patte = patte.replace(\"x[i3]\",str(inte+1))\n",
    "                        patte = patte.replace(\"i\",str(inte))\n",
    "\n",
    "                        exec(patte)\n",
    "\n",
    "                        LSE = LSE + (x[inte] - rest[inte])**2\n",
    "\n",
    "\n",
    "                if LSE < LSEX:\n",
    "                    LSEX = LSE\n",
    "                    result = rest.tolist()\n",
    "                    pattern = patted\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    print(\"dataset is: \", x)\n",
    "    print(\"resultant dataset is: \", result)\n",
    "    print(\"The expected pattern: \", pattern)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1187438f-5f3d-4e2c-9258-69e1df1da1fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = [1, 1, 2, 3, 5, 8, 13, 21]\n",
    "recognize(x,\"diff\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7edf70a0-7343-48de-b31f-35de00d4127a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%reset -f\n",
    "mem = list()\n",
    "mem2 = list()\n",
    "mem3 = list()\n",
    "known_values = list()\n",
    "\n",
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "#generates absolutely random babble\n",
    "def creativity_one():\n",
    "    y = \"\"\n",
    "    i = 1\n",
    "    while i < random.randint(1, 100):\n",
    "        x = chr(random.randint(32, 128))\n",
    "        y = y + x\n",
    "        i = i+1\n",
    "    return(str(y))\n",
    "\n",
    "#generates random babble, but only small letters\n",
    "def creativity_two():\n",
    "    y = \"\"\n",
    "    i = 1\n",
    "    while i < random.randint(1, 100):\n",
    "        x = chr(random.randint(97, 122))\n",
    "        y = y + x\n",
    "        i = i+1\n",
    "    return(str(y))\n",
    "\n",
    "\n",
    "#figures out if there's something right on the left or right of the random babble\n",
    "def leftrightcheck(x):\n",
    "    cori =[]\n",
    "    for j in range(0,len(x)):\n",
    "\n",
    "        try:\n",
    "            exec(str(x[j:len(x)]))\n",
    "            cori.append(str(x[j:len(x)]))\n",
    "            #print(\"correct right of\",j)\n",
    "        except SyntaxError:\n",
    "            qp=0\n",
    "            #print(\"something right right of\", j)\n",
    "        except:\n",
    "            qp=1\n",
    "\n",
    "        try:\n",
    "            exec(str(x[0:len(x)-j]))\n",
    "            cori.append(str(x[0:len(x)-j]))\n",
    "            #print(\"correct left of\",j)\n",
    "        except SyntaxError:\n",
    "            qp=0\n",
    "            #print(\"something right left of\", len(x)-j)\n",
    "        except:\n",
    "            qp=1\n",
    "    return(cori)\n",
    "\n",
    "# finds values such as ', $, #, [, ], (, ), ...\n",
    "def find_possible_values(x, known):\n",
    "    possible_values = list()\n",
    "    for i in x:\n",
    "        try:\n",
    "            exec(str(i))\n",
    "        except SyntaxError:\n",
    "            possible_values.append(str(i))\n",
    "            possible_values = list(dict.fromkeys(possible_values)) \n",
    "        except:\n",
    "            p=1\n",
    "    known = known + possible_values\n",
    "    known2 = list(dict.fromkeys(known)) \n",
    "    \n",
    "    return(known2)\n",
    "\n",
    "#finds possible combinations of the given output, where a random char has been replaced with ', $, [, ], (, ), ' or \" or so on.\n",
    "def possibilities(x,known):\n",
    "    x = x.replace(\"#\",\"\")\n",
    "    x = str(x)\n",
    "    l = len(x)\n",
    "    cori = []\n",
    "    for i in range(0,l):\n",
    "        for j in known:\n",
    "            y = x[0:i]+j+x[i+1:l]\n",
    "            y = y.replace(\"'\",\"\")\n",
    "            y = y.replace('\"','')\n",
    "            try:\n",
    "                exec(y)\n",
    "                cori.append(y)\n",
    "\n",
    "            except SyntaxError:\n",
    "                for k in range(0,len(y)):\n",
    "                    for h in known:\n",
    "                        z = y[0:k]+h+y[k+1:len(y)]\n",
    "                        z = z.replace(\"'\",\"\")\n",
    "                        z = z.replace('\"','')\n",
    "                        try:\n",
    "                            exec(z)\n",
    "                            cori.append(z)\n",
    "\n",
    "                        except:\n",
    "                            p=1\n",
    "            except:\n",
    "                p = 1\n",
    "\n",
    "\n",
    "    cori = list(dict.fromkeys(cori))\n",
    "    return(cori)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b7142a7-4477-435e-8d17-62b3d1f46558",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(100000):\n",
    "    x = creativity_one()\n",
    "    x = x.replace(\"#\",\"\")\n",
    "    try:\n",
    "        exec(x)\n",
    "        mem.append(x)\n",
    "        #print(\"correct in \",x, \"!\")\n",
    "    except SyntaxError:\n",
    "        #print(leftrightcheck(x))\n",
    "        known_values = find_possible_values(x,known_values)\n",
    "        #print(possibilities(x,known_values))\n",
    "    except:\n",
    "        p = 1\n",
    "    \n",
    "print(known_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "232517bc-bd64-437f-a17d-b839fc7ac513",
   "metadata": {},
   "outputs": [],
   "source": [
    "mem = list(dict.fromkeys(mem))\n",
    "print(mem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d93198aa-439b-4573-be27-a705eb4c2b88",
   "metadata": {},
   "outputs": [],
   "source": [
    "for j in range(50):\n",
    "    for i in range(1000000):\n",
    "        x = creativity_two()\n",
    "        try:\n",
    "            exec(x)\n",
    "            mem2.append(x)\n",
    "        #print(\"correct in \",x, \"!\")\n",
    "        except NameError:\n",
    "            p=0\n",
    "        #known_values = find_possible_values(x,known_values)\n",
    "        except SyntaxError:\n",
    "            mem2.append(x)\n",
    "        #print(possibilities(x,known_values))\n",
    "        except:\n",
    "            p = 1\n",
    "            \n",
    "mem2 = list(dict.fromkeys(mem2))\n",
    "print(mem2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f78bb53a-ac5b-47ad-b15b-c14212201f61",
   "metadata": {},
   "outputs": [],
   "source": [
    "spbk = \"\"\n",
    "for _ in range(1000):\n",
    "    n = random.randint(1, len(mem2)-1)\n",
    "    m = random.randint(1, len(mem)-1)\n",
    "    spbk = mem2[n] + mem[m]\n",
    "    #print(spbk)\n",
    "    try:\n",
    "        exec(spbk)\n",
    "        mem3.append(spbk)\n",
    "    except:\n",
    "        p=1\n",
    "\n",
    "mem3 = list(dict.fromkeys(mem3))\n",
    "print(mem3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f293e154",
   "metadata": {},
   "source": [
    "## Recognize mathematical pattern"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f18f1da",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def recognize(x, typ = \"reg\"):\n",
    "    operations = ['**','*','/','+','-']\n",
    "    #\n",
    "    ul = 11 #1000\n",
    "    ll = 0 #0\n",
    "\n",
    "    #\n",
    "    ul2 = 4 #100\n",
    "    ll2 = 1 #1\n",
    "\n",
    "    res = np.zeros(len(x))\n",
    "    print(\"type is: \",typ)\n",
    "    LSEX = 10000\n",
    "    q = 0\n",
    "\n",
    "    if len(x) < 3:\n",
    "\n",
    "        print(\"The dataset is too small\")\n",
    "\n",
    "    if len(x) >= 3:\n",
    "\n",
    "        for i in range(ll,ul):\n",
    "\n",
    "            for j in range(ll2,ul2):\n",
    "                q = i - 1\n",
    "                if i == 0:\n",
    "                    p = \"res[i] = \"+\"x[i1]\"                       \n",
    "\n",
    "                elif i > 0:\n",
    "                    p = \"res[i] = \" + str(q / j)   \n",
    "\n",
    "                for opr1 in operations: \n",
    "\n",
    "                        for k in range(ll,ul):\n",
    "                            for l in range(ll2,ul2):\n",
    "\n",
    "                                if k == 0:\n",
    "                                    pat = p + str(opr1) +\"x[i2]\" \n",
    "                                    #print(pat)\n",
    "                                elif k > 0:\n",
    "                                    pat = p + str(opr1) + str(k / l)\n",
    "                                    #print(pat)\n",
    "\n",
    "\n",
    "                                for opr2 in operations: \n",
    "\n",
    "                                    for g in range(ll,ul):\n",
    "                                        for h in range(ll2,ul2):\n",
    "                                            if str(opr2) == '**':\n",
    "                                                break\n",
    "\n",
    "                                            if g == 0:\n",
    "                                                patt = pat + str(opr2) +\"x[i3]\" \n",
    "                                                #print(patt)\n",
    "                                            elif g > 0:\n",
    "                                                patt = pat + str(opr2) + str(g / h)\n",
    "                                                #print(patt)\n",
    "\n",
    "                                            LSE = 0\n",
    "\n",
    "                                            if typ == \"diff\":\n",
    "                                                res = np.zeros(len(x)-1)\n",
    "                                            elif typ == \"reg\":\n",
    "                                                res = np.zeros(len(x))\n",
    "\n",
    "\n",
    "                                            for inte in range(len(x)):\n",
    "\n",
    "                                                if typ == \"diff\":\n",
    "\n",
    "                                                    if inte == 0:\n",
    "                                                        continue\n",
    "\n",
    "                                                    elif inte >= 1:\n",
    "                                                        pattern = patt.replace(\"i1\",str(inte-1))\n",
    "                                                        pattern = pattern.replace(\"i2\",str(inte-2))\n",
    "                                                        pattern = pattern.replace(\"i3\",str(inte-3))\n",
    "                                                        pattern = pattern.replace(\"i\",str(inte-1))\n",
    "\n",
    "                                                    try:\n",
    "                                                        exec(pattern)\n",
    "                                                    except:\n",
    "                                                        exec(\"res[\"+str(inte-1)+\"] = 0\")\n",
    "\n",
    "                                                    if inte == 0:\n",
    "                                                        LSE = 0\n",
    "\n",
    "                                                    elif inte >= 1:\n",
    "                                                        LSE = LSE + (x[(inte)] - res[inte-1])**2\n",
    "\n",
    "                                                if typ == \"reg\":\n",
    "\n",
    "                                                    if patt == 'res[i] = x[i1]**x[i2]**x[i3]':\n",
    "                                                        patt = 'res[i] = x[i1]**x[i2]'\n",
    "                                                    pattern = patt.replace(\"x[i1]\",str(inte+1))\n",
    "                                                    pattern = pattern.replace(\"x[i2]\",str(inte+1))\n",
    "                                                    pattern = pattern.replace(\"x[i3]\",str(inte+1))\n",
    "                                                    pattern = pattern.replace(\"i\",str(inte))\n",
    "\n",
    "                                                    exec(pattern)\n",
    "                                                    LSE = LSE + (x[inte] - res[inte])**2\n",
    "\n",
    "                                            if LSE < LSEX:\n",
    "                                                LSEX = LSE\n",
    "                                                result = res.tolist()\n",
    "                                                patterne = patt\n",
    "\n",
    "    pattern = patterne\n",
    "    p = 0\n",
    "    q = 0\n",
    "    lst = []\n",
    "    lste = \"\"\n",
    "    for i in range(len(patterne)):\n",
    "\n",
    "        try:\n",
    "            if type(int(patterne[i])) == int and patterne[i-1] != \"i\":\n",
    "                lste = str(lste) + str(patterne[i])\n",
    "            if i == len(patterne)-1 and len(lste) >=1:\n",
    "                lst.append(lste)\n",
    "        except ValueError:\n",
    "            if patterne[i] == \".\":\n",
    "                lste = str(lste) + str(patterne[i])\n",
    "            elif len(lste) >= 1:\n",
    "                lst.append(lste)\n",
    "                lste = \"\"\n",
    "\n",
    "    for i in range(len(lst)):\n",
    "\n",
    "        if len(lst) > 1 and i == 0:\n",
    "            p = float(lst[i])\n",
    "            q = float(lst[i+1])\n",
    "        elif len(lst) == 1:\n",
    "            p = float(patterne[lst[i]])\n",
    "\n",
    "        for j in range(1,11):\n",
    "            p1 = (p + 1/4 - 1/j)\n",
    "\n",
    "            for k in range(1,11):\n",
    "\n",
    "                if q != 0:\n",
    "                    q1 = (q + 1/4 - 1/k)\n",
    "                    if q1 == 0:\n",
    "                        q1 = 0.01\n",
    "\n",
    "                LSE = 0\n",
    "                patted = patterne.replace(\"res\",\"rest\")\n",
    "\n",
    "                if typ == \"diff\":\n",
    "                    rest = np.zeros(len(x)-1)\n",
    "\n",
    "                elif typ == \"reg\":\n",
    "                    rest = np.zeros(len(x))           \n",
    "\n",
    "                for inte in range(len(x)):\n",
    "\n",
    "                    patted = patted.replace(str(p), str(p1))\n",
    "\n",
    "                    if q != 0:\n",
    "                        patted = patted.replace(str(q), str(q1))\n",
    "\n",
    "                    if typ == \"diff\":\n",
    "                        if inte == 0:\n",
    "                            continue\n",
    "\n",
    "                        elif inte >= 1:\n",
    "                            patte = patted.replace(\"i1\",str(inte-1))\n",
    "                            patte = patte.replace(\"i2\",str(inte-2))\n",
    "                            patte = patte.replace(\"i3\",str(inte-3))\n",
    "                            patte = patte.replace(\"i\",str(inte-1))\n",
    "\n",
    "                        exec(patte)\n",
    "\n",
    "                        if inte == 0:\n",
    "                            LSE = 0\n",
    "\n",
    "                        elif inte >= 1:\n",
    "                            LSE = LSE + (x[(inte)] - rest[inte-1])**2\n",
    "\n",
    "\n",
    "                    if typ == \"reg\":\n",
    "\n",
    "                        patte = patted.replace(\"x[i1]\",str(inte+1))\n",
    "                        patte = patte.replace(\"x[i2]\",str(inte+1))\n",
    "                        patte = patte.replace(\"x[i3]\",str(inte+1))\n",
    "                        patte = patte.replace(\"i\",str(inte))\n",
    "\n",
    "                        exec(patte)\n",
    "\n",
    "                        LSE = LSE + (x[inte] - rest[inte])**2\n",
    "\n",
    "\n",
    "                if LSE < LSEX:\n",
    "                    LSEX = LSE\n",
    "                    result = rest.tolist()\n",
    "                    pattern = patted\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    print(\"dataset is: \", x)\n",
    "    print(\"resultant dataset is: \", result)\n",
    "    print(\"The expected pattern: \", pattern)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27010d18",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = [1, 1, 2, 3, 5, 8, 13, 21]\n",
    "recognize(x,\"diff\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b2e3a80",
   "metadata": {},
   "source": [
    "## Write and run python file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a20903e",
   "metadata": {},
   "outputs": [],
   "source": [
    "brain2 = \"C:\\\\Users\\\\Markb\\\\OneDrive\\\\Skrivebord\\\\brain\\\\brain2.py\"\n",
    "\n",
    "with open('C:\\\\Users\\\\Markb\\\\OneDrive\\\\Skrivebord\\\\brain\\\\base_memory.txt') as f:\n",
    "    lines = f.readlines()\n",
    "\n",
    "#text = \"import xlsxwriter\\nworkbook = xlsxwriter.Workbook('C:\\\\\\\\Users\\\\\\\\Markb\\\\\\\\OneDrive\\\\\\\\Skrivebord\\\\\\\\brain\\\\\\\\Expenses01.xlsx')\\nworksheet = workbook.add_worksheet()\\nexpenses = (['Rent', 1000], ['Gas',   100], ['Food',  300],  ['Gym',    50],)\\nrow = 0\\ncol = 0\\nfor item, cost in (expenses):\\n    worksheet.write(row, col,item)\\n    worksheet.write(row, col + 1, cost)\\n    row += 1\\nworksheet.write(row, 0, 'Total')\\nworksheet.write(row, 1, '=SUM(B1:B4)')\\nworkbook.close()\"\n",
    "#f = open(brain2, \"w\")\n",
    "#f.write(text)\n",
    "#f.close()\n",
    "#exec(open(brain2).read())\n",
    "\n",
    "text = \"import xlsxwriter\\nworkbook = xlsxwriter.Workbook('Expenses01.xlsx')\\nworksheet = workbook.add_worksheet()\\nexpenses = (['Rent', 1000], ['Gas',   100], ['Food',  300],  ['Gym',    50],)\\nrow = 0\\ncol = 0\\nfor item, cost in (expenses):\\n    worksheet.write(row, col,item)\\n    worksheet.write(row, col + 1, cost)\\n    row += 1\\nworksheet.write(row, 0, 'Total')\\nworksheet.write(row, 1, '=SUM(B1:B4)')\\nworkbook.close()\"\n",
    "\n",
    "f = open(\"myfile.py\", \"w\")\n",
    "f.write(text)\n",
    "f.close()\n",
    "exec(open(\"myfile.py\").read())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41823c02",
   "metadata": {},
   "source": [
    "## Survival system?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b127ac63",
   "metadata": {},
   "outputs": [],
   "source": [
    "del memo\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "\n",
    "Surv = 1\n",
    "mem = []\n",
    "t = 0\n",
    "while t < 10:\n",
    "    try:\n",
    "        if memo['Actions'][t] > 0:\n",
    "            action = memo['Actions'][t]\n",
    "        elif memo['Actions'][t] <= 0:\n",
    "            action = round(np.random.normal(1, 3, 1)[0])\n",
    "    except:\n",
    "        action = round(np.random.normal(1, 3, 1)[0])\n",
    "        \n",
    "    Surv = Surv + action\n",
    "    \n",
    "    \n",
    "    if Surv > 200:\n",
    "        Surv = -1\n",
    "    \n",
    "    mem.append([action,Surv])\n",
    "    t = t + 1\n",
    "\n",
    "\n",
    "    \n",
    "try:\n",
    "    for i in range(len(mem)):\n",
    "        if memo['Actions'][i] <= 0:\n",
    "            memo['Actions'][i] = mem[i][0]\n",
    "            \n",
    "    for i in range(len(memo)):\n",
    "        if i == 0:\n",
    "            memo['Survival points'][i] = 1\n",
    "        elif i > 0:\n",
    "            memo['Survival points'][i] = memo['Survival points'][i-1] + memo['Actions'][i-1]\n",
    "    display(memo)\n",
    "    \n",
    "except NameError:\n",
    "    memo = pd.DataFrame(mem, columns = ['Actions','Survival points'])\n",
    "    display(memo)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84f1804f",
   "metadata": {},
   "outputs": [],
   "source": [
    "## finance AI?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8158dbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mytarget(barsupfront, df):\n",
    "    \n",
    "    #Target flexible way\n",
    "    \n",
    "    pipdiff = 500*1e-5 #for TP\n",
    "\n",
    "    SLTPRatio = 2 #pipdiff/Ratio gives SL\n",
    "    \n",
    "    length = len(df)\n",
    "    high = list(df['High'])\n",
    "    low = list(df['Low'])\n",
    "    close = list(df['Close'])\n",
    "    open = list(df['Open'])\n",
    "    trendcat = [None] * length\n",
    "    \n",
    "    for line in range (0,length-barsupfront-2):\n",
    "        valueOpenLow = 0\n",
    "        valueOpenHigh = 0\n",
    "        for i in range(1,barsupfront+2):\n",
    "            value1 = open[line+1]-low[line+i]\n",
    "            value2 = open[line+1]-high[line+i]\n",
    "            valueOpenLow = max(value1, valueOpenLow)\n",
    "            valueOpenHigh = min(value2, valueOpenHigh)\n",
    "\n",
    "            if ( (valueOpenLow >= pipdiff) and (-valueOpenHigh <= (pipdiff/SLTPRatio)) ):\n",
    "                trendcat[line] = 1 #-1 downtrend\n",
    "                break\n",
    "            elif ( (valueOpenLow <= (pipdiff/SLTPRatio)) and (-valueOpenHigh >= pipdiff) ):\n",
    "                trendcat[line] = 2 # uptrend\n",
    "                break\n",
    "            else:\n",
    "                trendcat[line] = 0 # no clear trend\n",
    "            \n",
    "    return trendcat\n",
    "\n",
    "def signal_generator(df):\n",
    "    Open = df.Open.iloc[-1]\n",
    "    close = df.Close.iloc[-1]\n",
    "    previous_open = df.Open.iloc[-2]\n",
    "    previous_close = df.Close.iloc[-2]\n",
    "    \n",
    "    # Bearish Pattern\n",
    "    if (Open>close and \n",
    "    previous_open<previous_close and \n",
    "    close<previous_open and\n",
    "    Open>=previous_close):\n",
    "        return 1\n",
    "\n",
    "    # Bullish Pattern\n",
    "    elif (Open<close and \n",
    "        previous_open>previous_close and \n",
    "        close>previous_open and\n",
    "        Open<=previous_close):\n",
    "        return 2\n",
    "    \n",
    "    # No clear pattern\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "# dates in correct format for yahoo finance.\n",
    "today = date.today() \n",
    "today = datetime(today.year,today.month,today.day) #today\n",
    "one = datetime(today.year-1,today.month,today.day) #one year ago\n",
    "three = datetime(today.year-3,today.month,today.day) #three years ago\n",
    "five = datetime(today.year-5,today.month,today.day) #five years ago\n",
    "ten = datetime(today.year-10,today.month,today.day) #ten years ago\n",
    "twenty = datetime(today.year-20,today.month,today.day) #twenty years ago\n",
    "\n",
    "backrollingN = 6\n",
    "\n",
    "df = sdata(\"MSFT\", ten, today)\n",
    "df = df[['Open','High','Low','Close','Volume']]\n",
    "\n",
    "signal = []\n",
    "signal.append(0)\n",
    "for i in range(1,len(df)):\n",
    "    daf = df[i-1:i+1]\n",
    "    signal.append(signal_generator(daf))\n",
    "df[\"signal\"] = signal\n",
    "\n",
    "df.signal.value_counts()\n",
    "\n",
    "\n",
    "#Check if any zero volumes are available\n",
    "indexZeros = df[ df['Volume'] == 0 ].index\n",
    "df.drop(indexZeros , inplace=True)\n",
    "display(df.isna().sum())\n",
    "\n",
    "df['ATR'] = df.ta.atr(length=20)\n",
    "df['RSI'] = df.ta.rsi()\n",
    "df['RSISlope'] = df['RSI'].rolling(window=backrollingN).apply(get_slope, raw=True)\n",
    "df['Average'] = df.ta.midprice(length=1) #midprice\n",
    "df['AverageSlope'] = df['Average'].rolling(window=backrollingN).apply(get_slope, raw=True)\n",
    "\n",
    "for i in ['40', '80', '160']:\n",
    "    stf = 'MA' + i\n",
    "    slf = 'slopeMA'+i\n",
    "    df[stf] = df.ta.sma(length=int(i))\n",
    "    df[slf] = df[stf].rolling(window=backrollingN).apply(get_slope, raw=True)\n",
    "\n",
    "df['mytarget'] = mytarget(16, df)\n",
    "\n",
    "display(df)\n",
    "\n",
    "df_model= df\n",
    "df_model=df_model.dropna()\n",
    "\n",
    "df_up=df.RSI[ df['mytarget'] == 2 ]\n",
    "df_down=df.RSI[ df['mytarget'] == 1 ]\n",
    "df_unclear=df.RSI[ df['mytarget'] == 0 ]\n",
    "\n",
    "plt.hist(df_unclear, bins=100, alpha=0.5, label='unclear')\n",
    "plt.hist(df_down, bins=100, alpha=0.5, label='down')\n",
    "plt.hist(df_up, bins=100, alpha=0.5, label='up')\n",
    "\n",
    "plt.legend(loc='upper right')\n",
    "plt.show()\n",
    "\n",
    "fig = plt.figure(figsize = (15,20))\n",
    "ax = fig.gca()\n",
    "df_model.hist(ax = ax, bins=100)\n",
    "plt.show()\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from xgboost import plot_importance\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "attributes=['Open','Close','High','Low','Volume','ATR', 'RSI', 'Average', 'MA40', 'MA80', 'MA160', 'slopeMA40', 'slopeMA80', 'slopeMA160', 'AverageSlope', 'RSISlope']\n",
    "X = df_model[attributes]\n",
    "\n",
    "#the y is the target variable to predict.\n",
    "y = df_model[\"mytarget\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1) # random sampling\n",
    "\n",
    "#sequential sampling\n",
    "#train_index = int(0.8 * len(X))\n",
    "#X_train, X_test = X[:train_index], X[train_index:]\n",
    "#y_train, y_test = y[:train_index], y[train_index:]\n",
    "\n",
    "model = XGBClassifier()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "pred_train = model.predict(X_train)\n",
    "pred_test = model.predict(X_test)\n",
    "acc_train = accuracy_score(y_train, pred_train)\n",
    "acc_test = accuracy_score(y_test, pred_test)\n",
    "print('****Train Results****')\n",
    "print(\"Accuracy: {:.4%}\".format(acc_train))\n",
    "print('****Test Results****')\n",
    "print(\"Accuracy: {:.4%}\".format(acc_test))\n",
    "\n",
    "#--- How should I compare my accuracy ?\n",
    "print(df_model['mytarget'].value_counts()*100/df_model['mytarget'].count())\n",
    "\n",
    "# Random Model, gambler?\n",
    "pred_test = np.random.choice([0, 1, 2], len(y_test))\n",
    "accuracy_test = accuracy_score(y_test, pred_test)\n",
    "print(\"Accuracy Gambler: %.2f%%\" % (accuracy_test * 100.0))\n",
    "\n",
    "#plot feature importance\n",
    "plot_importance(model)\n",
    "plt.show()\n",
    "\n",
    "#for at lave predictions skal modellen have alle de satte features\n",
    "\n",
    "ny_test = X.tail(10)\n",
    "model.predict(ny_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "087a2fb5",
   "metadata": {},
   "source": [
    "## Automatic CV Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dae6e2dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "Loc = \"DK\"\n",
    "Lang = \"English\"\n",
    "navn = \"Mark Brezina\"\n",
    "website = \"Recruiter\"\n",
    "rolle = \"Dataanalytiker\"\n",
    "companj = \"Joe And the Juice\"\n",
    "\n",
    "if Loc == \"UK\":\n",
    "    sted = \"London SE1 4LN\"\n",
    "elif Loc == \"DK\":\n",
    "    sted = \"Hvidovre, København\"\n",
    "\n",
    "info = str(sted) +\" • \"+\"markbrezina2123@gmail.com • (+45)31772722\\nMDBrezina.com • linkedin.com/in/markbbrezina\\n\"\n",
    "\n",
    "erstat = [\"\\\\n\",\"[\",\"]\",\",\",\"'\",\".\"]\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "def laes(file):\n",
    "    file = str(file)+'.txt'\n",
    "    with open(file) as f:\n",
    "        lines = f.readlines()\n",
    "        lines = str(lines)\n",
    "        lines = lines.lower()\n",
    "        for i in erstat:\n",
    "            lines = lines.replace(i, \"\")\n",
    "        lines = lines.replace(\"  \", \" \")\n",
    "    lines = lines.split(\" \")\n",
    "    return(lines)\n",
    "\n",
    "tekst = laes('read')\n",
    "\n",
    "def kriterietabel(navn):\n",
    "    p = pd.read_excel('autocvdata.xlsx',sheet_name=0)[navn]\n",
    "    p = [x for x in p if str(x) != 'nan']\n",
    "    return(p)\n",
    "\n",
    "company = kriterietabel('company')\n",
    "\n",
    "def tjek(tekst,krav):\n",
    "    j = ''\n",
    "    k = ''\n",
    "    ord = ['on','in','a','by','we', 'i', 'som', 'med']\n",
    "    l = []\n",
    "    for i in tekst:\n",
    "        if str(k+\" \"+j+\" \"+i) in krav:\n",
    "            l.append(str(j+\" \"+i+\" \"+i))\n",
    "        if str(j+\" \"+i) in krav:\n",
    "            l.append(str(j+\" \"+i))\n",
    "            \n",
    "        elif j in krav and i not in krav:\n",
    "            l.append(j)\n",
    "            \n",
    "        j = i\n",
    "        k = j\n",
    "    l = list(dict.fromkeys(l))\n",
    "    return(l)\n",
    "\n",
    "compani = tjek(tekst,company)\n",
    "navne = tjek(tekst,kriterietabel('name_male'))\n",
    "navne2 = tjek(tekst,kriterietabel('name_female'))\n",
    "role = tjek(tekst,kriterietabel('role'))\n",
    "\n",
    "def beslut():\n",
    "    liste = ['ai','bi','quant','analyst','finance','data','it']\n",
    "    n = []\n",
    "    m = []\n",
    "    result = []\n",
    "    for i in liste:\n",
    "        n.append([len(tjek(tekst, kriterietabel(i))),i])\n",
    "        m.append(len(tjek(tekst, kriterietabel(i))))\n",
    "    for p in range(2):\n",
    "        t = p\n",
    "        for j in range(len(m)):\n",
    "            if m[j] == max(m):\n",
    "                if p == 1:\n",
    "                    result.append(n[j+1][1])\n",
    "                else:\n",
    "                    result.append(n[j][1])\n",
    "            t=t+1\n",
    "        m.remove(max(m))\n",
    "    result = list(dict.fromkeys(result))\n",
    "    return(result)\n",
    "\n",
    "decis1 = beslut()\n",
    "\n",
    "import docx\n",
    "from docx.oxml.shared import OxmlElement\n",
    "from docx.oxml.ns import qn\n",
    "from docx.shared import Pt\n",
    "from docx.enum.text import WD_ALIGN_PARAGRAPH\n",
    "from docx.enum.table import WD_ALIGN_VERTICAL\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def FORMP(paragraph, style):\n",
    "    paragraph.alignment = 1\n",
    "    paragraph.paragraph_format.space_before = 0\n",
    "    paragraph.paragraph_format.space_after = 0\n",
    "    paragraph.paragraph_format.line_spacing = 1\n",
    "    paragraph.style = style\n",
    "\n",
    "def tekster(tekst,style, spacings,underline=False):\n",
    "    paragraph = doc.add_paragraph()\n",
    "    paragraph.alignment = spacings[0]\n",
    "    paragraph.paragraph_format.space_before = spacings[1]\n",
    "    paragraph.paragraph_format.space_after = spacings[2]\n",
    "    paragraph.paragraph_format.line_spacing = spacings[3]\n",
    "    paragraph.style = style\n",
    "    paragraph.add_run(tekst)\n",
    "    if underline != False:\n",
    "            p = paragraph._p  # p is the <w:p> XML element\n",
    "            pPr = p.get_or_add_pPr()\n",
    "            pBdr = OxmlElement('w:pBdr')\n",
    "            pPr.insert_element_before(pBdr,\n",
    "                'w:shd', 'w:tabs', 'w:suppressAutoHyphens', 'w:kinsoku', 'w:wordWrap',\n",
    "                'w:overflowPunct', 'w:topLinePunct', 'w:autoSpaceDE', 'w:autoSpaceDN',\n",
    "                'w:bidi', 'w:adjustRightInd', 'w:snapToGrid', 'w:spacing', 'w:ind',\n",
    "                'w:contextualSpacing', 'w:mirrorIndents', 'w:suppressOverlap', 'w:jc',\n",
    "                'w:textDirection', 'w:textAlignment', 'w:textboxTightWrap',\n",
    "                'w:outlineLvl', 'w:divId', 'w:cnfStyle', 'w:rPr', 'w:sectPr',\n",
    "                'w:pPrChange'\n",
    "            )\n",
    "            bottom = OxmlElement('w:bottom')\n",
    "            bottom.set(qn('w:val'), 'single')\n",
    "            bottom.set(qn('w:sz'), '6')\n",
    "            bottom.set(qn('w:space'), '1')\n",
    "            bottom.set(qn('w:color'), 'auto')\n",
    "            pBdr.append(bottom)\n",
    "    \n",
    "def footer(tekst):\n",
    "    section = doc.sections[0]\n",
    "    footer = section.footer\n",
    "    footer_para = footer.paragraphs[0]\n",
    "    footer_para.alignment = 1\n",
    "    footer_para.text = tekst\n",
    "\n",
    "file = 'read.txt'\n",
    "with open(file) as f:\n",
    "    lines = f.readlines()\n",
    "    lines = str(lines)\n",
    "    for i in erstat:\n",
    "            lines = lines.replace(i, \"\")\n",
    "            \n",
    "jobopensoft = str(\"Can you give me the personality traits in this job opening? without descriptions\") + lines\n",
    "jobopenskills = str(\"Can you give me the technical skills in this job opening? without descriptions\") + lines\n",
    "jobopensub = str(\"can you tell me in one word what category this jobopening a finance, data science, IT, quantitative finance, business intelligence or investment job?\") + lines\n",
    "['ai','bi','quant','analyst','finance','data','it']\n",
    "import openai\n",
    "openai.api_key = \"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\"\n",
    "messages = [ {\"role\": \"system\", \"content\": \n",
    "              jobopensoft} ]\n",
    "chat = openai.ChatCompletion.create(model=\"gpt-3.5-turbo\", messages=messages)\n",
    "soft = chat.choices[0].message.content\n",
    "soft = soft.lower()\n",
    "soft = soft.replace(\"- \",\"\")\n",
    "if \"\\n\" in soft:\n",
    "    soft = soft.split(\"\\n\")\n",
    "elif \",\" in soft:\n",
    "    soft = soft.split(\",\")\n",
    "\n",
    "messages = [ {\"role\": \"system\", \"content\": \n",
    "              jobopenskills} ]\n",
    "chat = openai.ChatCompletion.create(model=\"gpt-3.5-turbo\", messages=messages)\n",
    "hard = chat.choices[0].message.content\n",
    "hard = hard.lower()\n",
    "hard = hard.replace(\"- \",\"\")\n",
    "hard = hard.replace(\"\\n\",\" \\n \")\n",
    "if \"\\n\" in hard:\n",
    "    hard = hard.split(\"\\n\")\n",
    "elif \",\" in hard:\n",
    "    hard = hard.split(\",\")\n",
    "    \n",
    "messages = [ {\"role\": \"system\", \"content\": \n",
    "              jobopensub} ]\n",
    "chat = openai.ChatCompletion.create(model=\"gpt-3.5-turbo\", messages=messages)\n",
    "classification = chat.choices[0].message.content\n",
    "classification = classification.lower()\n",
    "if classification == \"finance\" and \"finance\" in decis1:\n",
    "    sub = \"finance\"\n",
    "elif classification == \"data science\" and \"data\" in decis1:\n",
    "    sub = \"data\"\n",
    "elif classification == \"it\" and \"it\" in decis1:\n",
    "    sub = \"it\"\n",
    "elif (classification == \"quantitative finance.\" or classification == \"quantitative finance\" )and \"quant\" in decis1:\n",
    "    sub = \"quant\"\n",
    "elif classification == \"business intelligence\" and \"bi\" in decis1:\n",
    "    sub = \"bi\"\n",
    "elif classification == \"analyst\" and \"analyst\" in decis1:\n",
    "    sub = \"analyst\"\n",
    "else:\n",
    "    sub = [classification,decis1[0]]\n",
    "    \n",
    "    \n",
    "\n",
    "    \n",
    "if sub[0] == \"data science\":\n",
    "    sub[0] = \"data\"\n",
    "elif sub[0] == \"quantitative finance.\" or sub[0] == \"quantitative finance\" :\n",
    "    sub[0] = \"quant\"\n",
    "elif sub[0] == \"business intelligence\" or sub[0] == \"business intelligence.\":\n",
    "    sub[0] = \"bi\"\n",
    "\n",
    "print(soft)\n",
    "print(hard)\n",
    "print(compani)\n",
    "sub = \"all\"\n",
    "print(sub)\n",
    "\n",
    "if Lang == \"English\":\n",
    "    if not compani:\n",
    "        compani = companj\n",
    "    elif len(compani)>1:\n",
    "        compani = compani[0]\n",
    "    else:\n",
    "        compani = str(compani)\n",
    "        for i in erstat:\n",
    "            compani = compani.replace(i, \"\")\n",
    "        \n",
    "    objective = soft[1][0:len(soft[1])] + \" and \" + soft[2][0:len(soft[2])] + \" mathematics student seeking a position with your team at \"+ compani +\", where I can apply my skills in \" + hard[1]+\", \" +hard[2]+\" and \"+ hard[3] +\" to contribute to \"+compani+\"'s further development.\"\n",
    "    \n",
    "    #if \"quant\" in decis1 and \"quant\" in decis2:\n",
    "        #objective = objective + \"I like quant\"\n",
    "   #elif \"it\" in decis1 and \"it\" in decis2:\n",
    "        #objective = objective + \"I like quant\"\n",
    "   #elif \"finance\" in deics1 and \"finance\" in decis2:\n",
    "        #objective = objective + \"I like quant\"\n",
    "        \n",
    "elif Lang == \"Dansk\":\n",
    "    if not compani:\n",
    "        compani = companj\n",
    "    elif len(compani)>1:\n",
    "        compani = compani[0]\n",
    "    else:\n",
    "        compani = str(compani)\n",
    "        for i in erstat:\n",
    "            compani = compani.replace(i, \"\")\n",
    "    \n",
    "    objective = soft[1][0:len(soft[1])] + \" og \" + soft[2][0:len(soft[2])] + \" matematik studerende, som søger en stilling i jeres team, hos \"+ compani +\", hvor jeg håber på at få mulighed for at anvende mine evner indenfor \" + hard[1]+\", \"+ hard[2]+\" og \"+hard[3] +\" til at kunne bidrage til \" +compani+\"'s videre udvikling.\"\n",
    "    \n",
    "    #if \"quant\" in decis1 and \"quant\" in decis2:\n",
    "        #objective = objective + \"I like quant\"\n",
    "    #elif \"it\" in decis1 and \"it\" in decis2:\n",
    "        #objective = objective + \"I like quant\"\n",
    "    #elif \"finance\" in deics1 and \"finance\" in decis2:\n",
    "        #objective = objective + \"I like quant\"\n",
    "        \n",
    "        \n",
    "    #objective = \"Arbejde med varierende programmeringsopgaver og analyse opgaver.Programmering i SAS, SQL, VBA, R, Python, med C# og C++ i mindre grad.Analyse på lønsomhed, produktivitet, datakvalitet, profitabilitet, finans og ad-hoc emner.Analyse med statistik, regression, kvant metoder og mere.\\n\")\n",
    "\n",
    "    #objective = \"A goal-oriented data science and analytics employee with Python, SQL, and SAS programming experience in positions with focus on self-sufficiency, analytical skills and problem solving.\\n\"\n",
    "\n",
    "\n",
    "# Create a document\n",
    "from docx.dml.color import ColorFormat\n",
    "from docx.shared import RGBColor\n",
    "doc = docx.Document()\n",
    "\n",
    "style = doc.styles['Normal']\n",
    "font = style.font\n",
    "font.name = 'Times New Roman'\n",
    "font.size = Pt(11)\n",
    "bodys = doc.styles['Body Text']\n",
    "font = bodys.font\n",
    "font.name = 'Times New Roman'\n",
    "font.size = Pt(12)\n",
    "font.bold = True\n",
    "\n",
    "\n",
    "titler = doc.styles['Heading 1']\n",
    "font = titler.font\n",
    "font.name = 'Times New Roman'\n",
    "font.size = Pt(18)\n",
    "font.bold = True\n",
    "font.color.rgb = RGBColor(0, 0, 0)\n",
    "\n",
    "spacings = [1,0,0,1] \n",
    "\n",
    "#p_space = p.paragraph_format.line_spacing = 1\n",
    "\n",
    "if Lang == \"English\":\n",
    "        \n",
    "    #footer\n",
    "    footer(\"This CV and application was written automatically with Python\")\n",
    "    tekster(navn, titler, spacings, True)\n",
    "    tekster(info, style, spacings, False)\n",
    "    tekster(\"Objective\",bodys, spacings, True)\n",
    "    \n",
    "    p = doc.add_paragraph();p.alignment = 3\n",
    "    run = p.add_run(objective)\n",
    "    \n",
    "    tekster(\"Skills\",bodys, spacings, True)\n",
    "    table = doc.add_table(rows=3, cols=2)\n",
    "    hards = table.columns[0].cells\n",
    "    softs = table.columns[1].cells\n",
    "    for i in range(0,3):\n",
    "        hards[i].text = str(\"•\"+hard[i])\n",
    "        hards[i].paragraphs[0].alignment = WD_ALIGN_PARAGRAPH.CENTER\n",
    "        hards[i].paragraphs[0].alignment = WD_ALIGN_VERTICAL.CENTER\n",
    "        hards[i].paragraphs[0].paragraph_format.space_after = 0\n",
    "    for i in range(0,3):\n",
    "        softs[i].text = str(\"•\"+soft[i])\n",
    "        softs[i].paragraphs[0].alignment = WD_ALIGN_PARAGRAPH.CENTER\n",
    "        softs[i].paragraphs[0].alignment = WD_ALIGN_VERTICAL.CENTER\n",
    "        hards[i].paragraphs[0].paragraph_format.space_after = 0\n",
    "\n",
    "    tekster(\"Professional experience\",bodys, spacings, True)\n",
    "    \n",
    "    p = doc.add_paragraph();FORMP(p,style);p.alignment = 0\n",
    "    run = p.add_run(\"L&S Bank Copenhagen, Denmark\\n\");run.bold = True\n",
    "    run = p.add_run(\"Data science intern Jan23-Now\\n\");run.bold = True\n",
    "    run = p.add_run(\"• Mapped the underlying databases and analysed the data quality for the IRB data pipelines.\\n• Analysed and documented the data analysis process on high-risk customers and presented my findings to the head of internal revision and the head of credit.\\nDeveloped and maintained an automatized process for data quality assurance on datawarehouse tables.\\n•Assisted in the development and deployment of the data governance policy and framework.\\n\")\n",
    "\n",
    "    p = doc.add_paragraph();FORMP(p,style);p.alignment = 0\n",
    "    run = p.add_run(\"DJØF Copenhagen, Denmark\\n\");run.bold = True\n",
    "    run = p.add_run(\"VBA&Python instructor Jan23-Now\\n\");run.bold = True\n",
    "    run = p.add_run(\"• Led a series of courses on advanced Excel, Python, and VBA with an average of 20 students per course.\\n• Developed coursework for the courses in advanced VBA. Topics included nesting, connections to tables, pivottables and datamodels and the connection between windows applications within VBA/VBS.\\n\")\n",
    "\n",
    "    p = doc.add_paragraph();FORMP(p,style);p.alignment = 0\n",
    "    run = p.add_run(\"Statistics Denmark Copenhagen, Denmark\\n\");run.bold = True\n",
    "    run = p.add_run(\"Data analyst intern Sep21-Now\\n\");run.bold = True\n",
    "    run = p.add_run(\"• Developed analysis solutions, with a combination of Excel/VBA/VBS, SAS and SQL.\\n• Profitability and performance analysis of statistics projects associated with statistics sold. Key areas of the analysis were project income, project expenses, project duration, and number of hours spent.\\n•Documented the software architecture for the Donations system. Developed in a combination of C#, SQL, and Excel.\\n•Maintained and operated the timesheets and HR analysis systems. Developing further advances to analysis aspects and documentation of the underlying structure.\\n\")\n",
    "    \n",
    "    p = doc.add_paragraph()\n",
    "    \n",
    "    tekster(\"Education\",bodys, spacings, True)\n",
    "\n",
    "    p = doc.add_paragraph();FORMP(p,style);p.alignment = 0\n",
    "    run = p.add_run(\"UNIVERSITY OF COPENHAGEN\\t\\t\\t\\t\\tCopenhagen, Denmark\\nBachelor, Mathematical statistics\\t\\t\\t\\t        Graduation: Summer 2023\\n\")\n",
    "    run = p.add_run(\"Thesis: Stochastic volatility modelling for option pricing with implied volatility\\n\")\n",
    "    run = p.add_run(\"Relevant Coursework: General insurance mathematics, Life insurance mathematics, Stochastic processes, Mathematical statistics\\n\")\n",
    "\n",
    "    tekster(\"Certifications\",bodys, spacings, True)\n",
    "\n",
    "    if \"quant\" in sub or \"finance\" in sub or \"all\" in sub:\n",
    "        p = doc.add_paragraph('Foundations of financial risk certificate, GARP January 2021', style='List Bullet')\n",
    "        p.paragraph_format.line_spacing = 1\n",
    "        p = doc.add_paragraph('Risk management and credit principles certificate, NYIF edX June 2020', style='List Bullet')\n",
    "        p.paragraph_format.line_spacing = 1\n",
    "        p = doc.add_paragraph('Ratio analysis certificate, NYIF edX June 2020', style='List Bullet')\n",
    "        p.paragraph_format.line_spacing = 1\n",
    "        p = doc.add_paragraph('IBM Data Science Professional Certificate, IBM Coursera, April 2023', style='List Bullet')\n",
    "        p.paragraph_format.line_spacing = 1\n",
    "\n",
    "    if \"data\" in sub or \"analyst\" in sub or \"bi\" in sub or \"all\" in sub:\n",
    "        p = doc.add_paragraph('Professional certificate Data analysis, Microsoft edX, September 2020', style='List Bullet')\n",
    "        p.paragraph_format.line_spacing = 1\n",
    "        p = doc.add_paragraph('Microsoft Certified: Data Analyst Associate with Power BI, Microsoft Udemy, April 2023', style='List Bullet')\n",
    "        p.paragraph_format.line_spacing = 1\n",
    "\n",
    "    if \"finance\" in sub or \"all\" in sub:  \n",
    "        p = doc.add_paragraph('Professional Certificate Corporate Finance, ColumbiaX edX, September 2020', style='List Bullet')\n",
    "        p.paragraph_format.line_spacing = 1\n",
    "\n",
    "    if \"finance\" in sub or \"quant\" in sub or \"all\" in sub:\n",
    "        p = doc.add_paragraph('Macroeconometric Forecasting, IMF edX, September 2020', style='List Bullet')\n",
    "        p.paragraph_format.line_spacing = 1\n",
    "        p = doc.add_paragraph('Macroeconometric Diagnostics, IMF edX, July 2020', style='List Bullet')\n",
    "        p.paragraph_format.line_spacing = 1\n",
    "        p = doc.add_paragraph('Financial Market Analysis, IMF edX, September 2020', style='List Bullet')\n",
    "        p.paragraph_format.line_spacing = 1\n",
    "\n",
    "    if \"data\" in sub or \"analyst\" in sub or \"bi\" in sub or \"it\" in sub or \"all\" in sub:\n",
    "        p = doc.add_paragraph('Introductory courses in SAS, SAS institute with Statistics Denmark, September 2021 to now', style='List Bullet')\n",
    "        p.paragraph_format.line_spacing = 1\n",
    "        p = doc.add_paragraph('Advanced courses in SAS /w macros, SAS institute with Statistics Denmark, September 2021 to now', style='List Bullet')\n",
    "        p.paragraph_format.line_spacing = 1\n",
    "        p = doc.add_paragraph('Google Data Analytics Professional Certificate, Google Coursera, April 2023', style='List Bullet')\n",
    "        p.paragraph_format.line_spacing = 1  \n",
    "\n",
    "    if \"ai\" in sub or \"quant\" in sub or \"all\" in sub:\n",
    "        p = doc.add_paragraph('Data Science courses w/ Machine Learning: HarvardX edX, April 2023', style='List Bullet')\n",
    "        p.paragraph_format.line_spacing = 1\n",
    "        p = doc.add_paragraph('Data Science: Capstone project, HarvardX edX, April 2023', style='List Bullet')\n",
    "        p.paragraph_format.line_spacing = 1\n",
    "    elif \"data\" in sub or \"quant\" in sub or \"all\" in sub:\n",
    "        p = doc.add_paragraph('Data Science courses in Linear Regression; Wrangling; inference and modelling; Probability, HarvardX edX, April 2023', style='List Bullet')\n",
    "        p.paragraph_format.line_spacing = 1\n",
    "        p = doc.add_paragraph('IBM Data Science Professional Certificate, IBM Coursera, April 2023', style='List Bullet')\n",
    "        p.paragraph_format.line_spacing = 1 \n",
    "\n",
    "    tekster(\"Notable activities\",bodys, spacings, True)\n",
    "\n",
    "    if \"quant\" in sub or \"ai\" in sub or \"all\" in sub:\n",
    "        p = doc.add_paragraph()\n",
    "        FORMP(p,bodys)\n",
    "        p.alignment = 0\n",
    "        run = p.add_run(\"Modern portfolio theory in Python\")\n",
    "        p = doc.add_paragraph()\n",
    "        FORMP(p,style)\n",
    "        p.alignment = 0\n",
    "        run = p.add_run(\"Automated system for decision making on investment opportunities, with Markowitz Framework for portfolio optimization\")\n",
    "        run.font.italic = True\n",
    "        p = doc.add_paragraph()\n",
    "        FORMP(p,style)\n",
    "        p.alignment = 0\n",
    "        run = p.add_run(\"A spare time project on developing, deploying, and automating a decision-making system on investment opportunities, written in Python. The system deploys the Markowitz framework for quantitative portfolio management and a hand-made decision-making system. After completion, the results are automatically sent via email to family and friends.\")\n",
    "        \n",
    "        p = doc.add_paragraph()\n",
    "        FORMP(p,bodys)\n",
    "        p.alignment = 0\n",
    "        run = p.add_run(\"Stochastic volatility modelling in R\")\n",
    "        p = doc.add_paragraph()\n",
    "        FORMP(p,style)\n",
    "        p.alignment = 0\n",
    "        run = p.add_run(\"R Library for options pricing with implied volatility\")\n",
    "        run.font.italic = True\n",
    "        p = doc.add_paragraph()\n",
    "        FORMP(p,style)\n",
    "        p.alignment = 0\n",
    "        run = p.add_run(\"Developed a library in R, for analysis of options with the Heston Model for Stochastic Volatility.\\nThe library had a range of functions for various functionalities such as pricing, estimating moneyness, calculating implied volatility and plotting a volatility smile and a volatility surface.\")\n",
    "        \n",
    "        p = doc.add_paragraph()\n",
    "        FORMP(p,bodys)\n",
    "        p.alignment = 0\n",
    "        run = p.add_run(\"Machine learning in Python\")\n",
    "        p = doc.add_paragraph()\n",
    "        FORMP(p,style)\n",
    "        p.alignment = 0\n",
    "        run = p.add_run(\"Developed various analytic tools in Python for application at a future position\")\n",
    "        run.font.italic = True\n",
    "        p = doc.add_paragraph()\n",
    "        FORMP(p,style)\n",
    "        p.alignment = 0\n",
    "        run = p.add_run(\"Various ML algorithsm used for classifying and analysing stock price data. Linear regression, Decision trees, clustering algorithms, to solve prediction and classification problems.\")\n",
    "    \n",
    "    if \"data\" in sub or \"it\" in sub or \"all\" in sub:\n",
    "        p = doc.add_paragraph()\n",
    "        FORMP(p,bodys)\n",
    "        p.alignment = 0\n",
    "        p.paragraph_format.space_before = 2\n",
    "        run = p.add_run(\"Various IT projects\")\n",
    "        p = doc.add_paragraph()\n",
    "        FORMP(p,style)\n",
    "        p.alignment = 0\n",
    "        run = p.add_run(\"Custom excel workbook made with C#, SQL server setup and data warehouse documentation \")\n",
    "        run.font.italic = True\n",
    "        p = doc.add_paragraph()\n",
    "        FORMP(p,style)\n",
    "        p.alignment = 0\n",
    "        run = p.add_run(\"• Developing custom excel workbooks for Statistics Denmark, the workbooks are made with C# to contain custom taskpanes and taskbars unique to the workbook.\\n• Setting up an SQL server on my home PC, with Python and R accessing it for data analysis, as well as inserting new inputs and manipulating the data in tables on the server\\n• Automating various processes with the help of task schedulers, in combination with VBA, R, SAS/SQL or Python. Examples would be email reading and report generation for key company stakeholders.\\n• Documentation of various work related datawarehouses, with tools such as Dia from PortableApps, dbdiagram.io or bubbl.us\")\n",
    "\n",
    "        p = doc.add_paragraph()\n",
    "        FORMP(p,bodys)\n",
    "        p.alignment = 0\n",
    "        p.paragraph_format.space_before = 2\n",
    "        run = p.add_run(\"Data cleaning, preprocessing and exploratory data analysis in R\")\n",
    "        p = doc.add_paragraph()\n",
    "        FORMP(p,style)\n",
    "        p.alignment = 0\n",
    "        run = p.add_run(\"Data read, cleaning, preprocessing and basic descriptive statistics for a dataset\")\n",
    "        run.font.italic = True\n",
    "        p = doc.add_paragraph()\n",
    "        FORMP(p,style)\n",
    "        p.alignment = 0\n",
    "        run = p.add_run(\"• Automatic data read from the internet or from a common filetype, such as .csv, .txt, .xlsx or .rda.\\n• Cleaning out rows or cells with NAs either by removing the row or substituting the NA for the mean value, dividing the dataset into numerical areas and text areas. To better be able to process data with numerical analysis or categorical analysis.\\n• Basic descriptive statistics for the dataset separately for numerical data and categorical data such as means, standard deviation, variance, etc.\")\n",
    "    \n",
    "    if \"quant\" in sub or \"finance\" in sub or \"all\" in sub:\n",
    "        p = doc.add_paragraph()\n",
    "        FORMP(p,bodys)\n",
    "        p.alignment = 0\n",
    "        p.paragraph_format.space_before = 2\n",
    "        run = p.add_run(\"World of Warcraft auction house spoofing and flipping \")\n",
    "        p = doc.add_paragraph()\n",
    "        FORMP(p,style)\n",
    "        p.alignment = 0\n",
    "        run = p.add_run(\"A series of experiments conducted in the game World of Warcraft, focus was on earning ingame currency from trading on the auction house\")\n",
    "        run.font.italic = True\n",
    "        p = doc.add_paragraph()\n",
    "        FORMP(p,style)\n",
    "        p.alignment = 0\n",
    "        run = p.add_run(\"The video game World of Warcraft has an in-game auction house, in which players can trade goods of various kinds. In the game I conducted a series of experiments on spoofing and flipping goods. Whereby I cornered the markets for resources called linen cloth and wool cloth, changing the prices accessible by players to 10x the normal pricing. In the same scenario I put out more than a 1000 pieces of single bundled linen cloth at a bid price of 1 copper(1cent) and with a buyout price of 10 silver(10$ ?). To crowd out the market from competitors.\")\n",
    "\n",
    "        p = doc.add_paragraph()\n",
    "        FORMP(p,bodys)\n",
    "        p.alignment = 0\n",
    "        p.paragraph_format.space_before = 2\n",
    "        run = p.add_run(\"Steam market trading\")\n",
    "        p = doc.add_paragraph()\n",
    "        FORMP(p,style)\n",
    "        p.alignment = 0\n",
    "        run = p.add_run(\"Buying cases low and selling them high. 700€ profit\")\n",
    "        run.font.italic = True\n",
    "        p = doc.add_paragraph()\n",
    "        FORMP(p,style)\n",
    "        p.alignment = 0\n",
    "        run = p.add_run(\"The video game Counter strike:global offensive, has a unique system in place, where players can buy cases, essentially locked boxes with an opportunity to obtain ingame graphical upgrades, with varying popularity.\\nI've spent a year buying and selling these cases on a common marketplace accessible by all players. At current I've earned 400€, with an expectation of earning a further 300€ before July 2023.\")\n",
    "\n",
    "    \n",
    "    if \"bi\" in sub or \"analyst\" in sub or \"all\" in sub:\n",
    "        p = doc.add_paragraph()\n",
    "        FORMP(p,bodys)\n",
    "        p.alignment = 0\n",
    "        p.paragraph_format.space_before = 2\n",
    "        run = p.add_run(\"KPI and BI dashboards made with Python and SAS/VBA\")\n",
    "        p = doc.add_paragraph()\n",
    "        FORMP(p,style)\n",
    "        p.alignment = 0\n",
    "        run = p.add_run(\"Dashboards made for Statistics Denmark with VBA and redone at home with Python\")\n",
    "        run.font.italic = True\n",
    "        p = doc.add_paragraph()\n",
    "        FORMP(p,style)\n",
    "        p.alignment = 0\n",
    "        run = p.add_run(\"Exploratory data analysis, that lead into data visualization with Power BI and a series of spreadsheets used by management in Statistics Denmark to judge the economic progress\")\n",
    "\n",
    "        p = doc.add_paragraph()\n",
    "        FORMP(p,bodys)\n",
    "        p.alignment = 0\n",
    "        p.paragraph_format.space_before = 2\n",
    "        run = p.add_run(\"Timesheet/HR data analysis with SAS/VBA\")\n",
    "        p = doc.add_paragraph()\n",
    "        FORMP(p,style)\n",
    "        p.alignment = 0\n",
    "        run = p.add_run(\"Exploratory data analysis and KPI presentation\")\n",
    "        run.font.italic = True\n",
    "        p = doc.add_paragraph()\n",
    "        FORMP(p,style)\n",
    "        p.alignment = 0\n",
    "        run = p.add_run(\"Exploratory data analysis, concluding in the development of a routined and automatic SAS script to gather KPIs on significantly important timesheet statistics, result was presented as excel sheet table\")\n",
    "\n",
    "\n",
    "    if \"analyst\" in sub or \"ai\" in decis1  or \"quant\" in sub or \"all\" in sub:\n",
    "        p = doc.add_paragraph()\n",
    "        FORMP(p,bodys)\n",
    "        p.alignment = 0\n",
    "        p.paragraph_format.space_before = 2\n",
    "        run = p.add_run(\"Various python programming\")\n",
    "        p = doc.add_paragraph()\n",
    "        FORMP(p,style)\n",
    "        p.alignment = 0\n",
    "        run = p.add_run(\"Galaxy simulation in python and automatic CV generation\")\n",
    "        run.font.italic = True\n",
    "        p = doc.add_paragraph()\n",
    "        FORMP(p,style)\n",
    "        p.alignment = 0\n",
    "        run = p.add_run(\"In my sparetime I've been working on a series of galaxy simulations, at current the simulations hold the correct physics for motions in a gravitational field.\\n• For easily applying to a large amount of jobs, I've developed an automatic CV and Cover letter generator, based on my previous CV and cover letters, the process goes through a list of known key words and skills to sort out which ones I see myself having and than rebuilding the CV and coverletter to fit.\")\n",
    "\n",
    "elif Lang == \"Dansk\":\n",
    "        \n",
    "    #footer\n",
    "    footer(\"Dette CV og jobansøgning er skrevet automatisk med Python\")\n",
    "    #big title\n",
    "    tekster(navn, titler, spacings, True)\n",
    "    tekster(info, style, spacings, False)\n",
    "    tekster(\"Resumé\",bodys, spacings, True)\n",
    "    \n",
    "    p = doc.add_paragraph();p.alignment = 0\n",
    "    run = p.add_run(objective)\n",
    "    \n",
    "    #Hard skills\n",
    "    tekster(\"Kompetencer\",bodys, spacings, True)\n",
    "    table = doc.add_table(rows=3, cols=2)\n",
    "    hards = table.columns[0].cells\n",
    "    softs = table.columns[1].cells\n",
    "    for i in range(0,3):\n",
    "        hards[i].text = str(\"•\"+hard[i])\n",
    "        hards[i].paragraphs[0].alignment = WD_ALIGN_PARAGRAPH.CENTER\n",
    "        hards[i].paragraphs[0].alignment = WD_ALIGN_VERTICAL.CENTER\n",
    "        hards[i].paragraphs[0].paragraph_format.space_after = 0\n",
    "    for i in range(0,3):\n",
    "        softs[i].text = str(\"•\"+soft[i])\n",
    "        softs[i].paragraphs[0].alignment = WD_ALIGN_PARAGRAPH.CENTER\n",
    "        softs[i].paragraphs[0].alignment = WD_ALIGN_VERTICAL.CENTER\n",
    "        hards[i].paragraphs[0].paragraph_format.space_after = 0\n",
    "        \n",
    "    #Professional experience\n",
    "    tekster(\"Arbejdserfaring\",bodys, spacings, True)\n",
    "    \n",
    "    p = doc.add_paragraph();FORMP(p,style);p.alignment = 0\n",
    "    run = p.add_run(\"L&S Bank,  København\\n\");run.bold = True\n",
    "    run = p.add_run(\"Studentermedhjælper,  Jan23-Nu\\n\");run.bold = True\n",
    "    run = p.add_run(\"• Dokumenterede datawarehouse strukturen og analyserede datakvalitet på de 7 EBA guideline dimensioner mht. IRB proccesen.\\n• Analyserede og dokumenterede dataanalyse processen på højrisiko kunder, efterfølgende præsenterede jeg resultatet for kredit-chefen og senior mangeren hos Intern revision.\\nUdviklede en semi-automatisk proces til at undersøge datakvaliteten på tabeller i datawarehouse.\\n• Assisterede med at udvikle og implementere data governance politiken og dens tilhørende framework.\\n\")\n",
    "\n",
    "    p = doc.add_paragraph();FORMP(p,style);p.alignment = 0\n",
    "    run = p.add_run(\"DJØF,  København\\n\");run.bold = True\n",
    "    run = p.add_run(\"VBA & Python instruktør,  Jan23-Now\\n\");run.bold = True\n",
    "    run = p.add_run(\"• Fungerede instruktør og teknisk hjælp på en række kurser om avanceret Excel, Python, og VBA.\\n• Udviklede kursusmateriale til kurser om avanceret VBA. Med emner såsom nesting, tabeller, pivottabeller og forbindelser til andre windows applikationer med VBA/VBS.\\n\")\n",
    "\n",
    "    p = doc.add_paragraph();FORMP(p,style);p.alignment = 0\n",
    "    run = p.add_run(\"Danmarks statistik,  København\\n\");run.bold = True\n",
    "    run = p.add_run(\"Studentermedhjælper,  Sep21-Nu\\n\");run.bold = True\n",
    "    run = p.add_run(\"• Udviklede analyseværktøjer, med en kombination af Excel/VBA/VBS, SAS og SQL.\\n• Profit og performance analyser af virksomhedens produkter, sammenholdt med salg. Med interesseområderne produkt indkomst, udgift, tidsforbrug, og produkttype.\\n•Dokumenterede den underliggende IT-struktur for donationssystemet. Udviklet i en kombination af C#, SQL, og Excel.\\n• vedligeholde og udførte analyse med tidsregistreringssystemet. videreudviklede derudover på analyse delene og dokumentationen af den underliggende struktur.\\n\")\n",
    "    \n",
    "    #education\n",
    "    tekster(\"Uddanelse\",bodys, spacings, True)\n",
    "\n",
    "    p = doc.add_paragraph();FORMP(p,style);p.alignment = 0\n",
    "    run = p.add_run(\"Københavns universitet,  København\\nBachelor: Matematik-statistik, Sep19-Jun23\\n\")\n",
    "    run = p.add_run(\"Bachelorprojekt: Stokastisk volatilitets modellering mht. optionsprisfastsættelse med implied volatility\\n\")\n",
    "    run = p.add_run(\"Relevante kurser: skadesforsikring, livsforsikring, Stokastike processer, Matematisk statistik\\n\")\n",
    "    \n",
    "    p = doc.add_paragraph()\n",
    "    \n",
    "    #certifications\n",
    "    tekster(\"Certifikater\",bodys, spacings, True)\n",
    "\n",
    "\n",
    "    if \"quant\" in sub or \"finance\" in sub or \"all\" in sub:\n",
    "        p = doc.add_paragraph('Foundations of financial risk certificate, GARP January 2021', style='List Bullet')\n",
    "        p.paragraph_format.line_spacing = 1\n",
    "        p = doc.add_paragraph('Risk management and credit principles certificate, NYIF edX June 2020', style='List Bullet')\n",
    "        p.paragraph_format.line_spacing = 1\n",
    "        p = doc.add_paragraph('Ratio analysis certificate, NYIF edX June 2020', style='List Bullet')\n",
    "        p.paragraph_format.line_spacing = 1\n",
    "        p = doc.add_paragraph('IBM Data Science Professional Certificate, IBM Coursera, April 2023', style='List Bullet')\n",
    "        p.paragraph_format.line_spacing = 1\n",
    "\n",
    "    if \"data\" in sub or \"analyst\" in sub or \"bi\" in sub or \"all\" in sub:\n",
    "        p = doc.add_paragraph('Professional certificate Data analysis, Microsoft edX, September 2020', style='List Bullet')\n",
    "        p.paragraph_format.line_spacing = 1\n",
    "        p = doc.add_paragraph('Microsoft Certified: Data Analyst Associate with Power BI, Microsoft Udemy, April 2023', style='List Bullet')\n",
    "        p.paragraph_format.line_spacing = 1\n",
    "        \n",
    "\n",
    "    if \"finance\" in sub or \"all\" in sub:  \n",
    "        p = doc.add_paragraph('Professional Certificate Corporate Finance, ColumbiaX edX, September 2020', style='List Bullet')\n",
    "        p.paragraph_format.line_spacing = 1\n",
    "\n",
    "    if \"finance\" in sub or \"quant\" in sub or \"all\" in sub:\n",
    "        p = doc.add_paragraph('Macroeconometric Forecasting, IMF edX, September 2020', style='List Bullet')\n",
    "        p.paragraph_format.line_spacing = 1\n",
    "        p = doc.add_paragraph('Macroeconometric Diagnostics, IMF edX, July 2020', style='List Bullet')\n",
    "        p.paragraph_format.line_spacing = 1\n",
    "        p = doc.add_paragraph('Financial Market Analysis, IMF edX, September 2020', style='List Bullet')\n",
    "        p.paragraph_format.line_spacing = 1\n",
    "\n",
    "    if \"data\" in sub or \"analyst\" in sub or \"bi\" in sub or \"it\" in sub or \"all\" in sub:\n",
    "        p = doc.add_paragraph('Introductory courses in SAS, SAS institute with Statistics Denmark, September 2021 to now', style='List Bullet')\n",
    "        p.paragraph_format.line_spacing = 1\n",
    "        p = doc.add_paragraph('Advanced courses in SAS /w macros, SAS institute with Statistics Denmark, September 2021 to now', style='List Bullet')\n",
    "        p.paragraph_format.line_spacing = 1\n",
    "        p = doc.add_paragraph('Google Data Analytics Professional Certificate, Google Coursera, April 2023', style='List Bullet')\n",
    "        p.paragraph_format.line_spacing = 1\n",
    "        \n",
    "\n",
    "    if \"ai\" in sub or \"quant\" in sub or \"all\" in sub:\n",
    "        p = doc.add_paragraph('Data Science courses w/ Machine Learning: HarvardX edX, April 2023', style='List Bullet')\n",
    "        p.paragraph_format.line_spacing = 1\n",
    "        p = doc.add_paragraph('Data Science: Capstone project, HarvardX edX, April 2023', style='List Bullet')\n",
    "        p.paragraph_format.line_spacing = 1\n",
    "    elif \"data\" in sub or \"quant\" in sub:\n",
    "        p = doc.add_paragraph('Data Science courses in Linear Regression; Wrangling; inference and modelling; Probability, HarvardX edX, April 2023', style='List Bullet')\n",
    "        p.paragraph_format.line_spacing = 1\n",
    "        p = doc.add_paragraph('IBM Data Science Professional Certificate, IBM Coursera, April 2023', style='List Bullet')\n",
    "        p.paragraph_format.line_spacing = 1\n",
    "        \n",
    "#Summary\n",
    "    tekster(\"Relevante aktiviter\",bodys, spacings, True)\n",
    "\n",
    "    if \"quant\" in sub or \"ai\" in sub or \"all\" in sub:\n",
    "        p = doc.add_paragraph()\n",
    "        FORMP(p,bodys)\n",
    "        p.alignment = 0\n",
    "        run = p.add_run(\"MPT in Python\")\n",
    "        p = doc.add_paragraph()\n",
    "        FORMP(p,style)\n",
    "        p.alignment = 0\n",
    "        run = p.add_run(\"Automatisk system til at hjælpe med at beslutte hvilke investeringsmuligheder der er bedst\")\n",
    "        run.font.italic = True\n",
    "        p = doc.add_paragraph()\n",
    "        FORMP(p,style)\n",
    "        p.alignment = 0\n",
    "        run = p.add_run(\"Frtids projekt om udvikling og automatisering af beslutningsprocessen på investeringsmuligheder, altsammen skrevet i Python. Systemet anvender Markowitz metoden til kvantitative portføljestyring og et beslutningssystem, som undersøger virksomhedens fundamentale værdier.\")\n",
    "        \n",
    "        p = doc.add_paragraph()\n",
    "        FORMP(p,bodys)\n",
    "        p.alignment = 0\n",
    "        run = p.add_run(\"Stokastisk volatilitets modeller skrevet i R\")\n",
    "        p = doc.add_paragraph()\n",
    "        FORMP(p,style)\n",
    "        p.alignment = 0\n",
    "        run = p.add_run(\"Udvikling af et bibliotek i R til brug mht. optionsprisfastsættelse med Implied volatility og mere specifikt Heston Modellen\")\n",
    "        run.font.italic = True\n",
    "        p = doc.add_paragraph()\n",
    "        FORMP(p,style)\n",
    "        p.alignment = 0\n",
    "        run = p.add_run(\"Mit bachelorprojekt har fokus på udvikling af et bibliotek i R, som skal bruges af virksomheden EnvisionRisk, til optionsprisfastsættelse med Implied volatility i Heston Modellen. I biblioteket er udviklet prisfastsættelses funktionerne ud fra Heston modellen, Black-scholes, volatilitetssmil og volatilitetsflader, samt to simulationsfunktioner til mere specifikke opgaver.\")\n",
    "        \n",
    "        p = doc.add_paragraph()\n",
    "        FORMP(p,bodys)\n",
    "        p.alignment = 0\n",
    "        run = p.add_run(\"Machine learning og AI med Python\")\n",
    "        p = doc.add_paragraph()\n",
    "        FORMP(p,style)\n",
    "        p.alignment = 0\n",
    "        run = p.add_run(\"Forskellige mindre opgaver med machine learning og AI, som jeg bruger til at gøre mit liv lettere.\")\n",
    "        run.font.italic = True\n",
    "        p = doc.add_paragraph()\n",
    "        FORMP(p,style)\n",
    "        p.alignment = 0\n",
    "        run = p.add_run(\"Her er der f.eks. tale om deicison trees og clustering algoritmer, som jeg bruger til diverse regressions opgaver og en lille smule af i mit autoCV. Derudover arbejder jeg en del med LTSM og CNN, som er AI algoritmer, disse skal bruges til en udvidet version af mit MPT program. Jeg kigger også pt på object identification og computer vision programmer, som jeg vil bruge til udvikling af en lille robot, der tjekker vejret for mig.\")\n",
    "        \n",
    "     \n",
    "    \n",
    "    if \"data\" in sub or \"it\" in sub or \"all\" in sub:\n",
    "        p = doc.add_paragraph()\n",
    "        FORMP(p,bodys)\n",
    "        p.alignment = 0\n",
    "        p.paragraph_format.space_before = 2\n",
    "        run = p.add_run(\"Forskellige IT projekter\")\n",
    "        p = doc.add_paragraph()\n",
    "        FORMP(p,style)\n",
    "        p.alignment = 0\n",
    "        run = p.add_run(\"Excel workbook med C#, SQL server opsætning, Docker+Kubernetes opsætning \")\n",
    "        run.font.italic = True\n",
    "        p = doc.add_paragraph()\n",
    "        FORMP(p,style)\n",
    "        p.alignment = 0\n",
    "        run = p.add_run(\"Udvikling af en unik Excel workbook for Danmarks statistik, Workbooken skal laves med C# og skal indeholde brugerdefinerede taskbanes og taskbars med unikke funktionaliteter\\nOpsætning af en SQL server på min hjemmecomputer, med Python og R adgang, så jeg kan indsætte og manipulere data på serveren\\nOpsætning af Docker+Kubernetes server, så jeg kan tilgå min kode fra hvorsomhelst.\")\n",
    "\n",
    "        p = doc.add_paragraph()\n",
    "        FORMP(p,bodys)\n",
    "        p.alignment = 0\n",
    "        p.paragraph_format.space_before = 2\n",
    "        run = p.add_run(\"Data cleaning, preprocessing og exploratory data analysis i R\")\n",
    "        p = doc.add_paragraph()\n",
    "        FORMP(p,style)\n",
    "        p.alignment = 0\n",
    "        run = p.add_run(\"Data indlæsning, cleaning, preprocessing og basal statistik på datasættet\")\n",
    "        run.font.italic = True\n",
    "        p = doc.add_paragraph()\n",
    "        FORMP(p,style)\n",
    "        p.alignment = 0\n",
    "        run = p.add_run(\"• Automatisk data indlæsning fra internettet eller fra velkendte filtyper, så som .csv, .txt, .xlsx eller .rda.\\n• Cleaning af rækker eller celler med NAs enten ved at fjerne rækker/celler eller ved at erstatte NA med middel værdien, inddeling af datasættet i numerisk og tekst kolonner. for bedre at kunne udføre numerisk eller kategorisk analyse.\\n• Basal statistik for datasættet, her bestemmes f.eks. middelværdi, standardafvigelse og varians.\")\n",
    "    \n",
    "    \n",
    "    if \"bi\" in sub or \"analyst\" in sub or \"all\" in sub:\n",
    "        p = doc.add_paragraph()\n",
    "        FORMP(p,bodys)\n",
    "        p.alignment = 0\n",
    "        p.paragraph_format.space_before = 2\n",
    "        run = p.add_run(\"KPI og BI dashboards lavet med Python og SAS/VBA\")\n",
    "        p = doc.add_paragraph()\n",
    "        FORMP(p,style)\n",
    "        p.alignment = 0\n",
    "        run = p.add_run(\"Dashboards lavet som prototyper til Danmarks med VBA og Python\")\n",
    "        run.font.italic = True\n",
    "        p = doc.add_paragraph()\n",
    "        FORMP(p,style)\n",
    "        p.alignment = 0\n",
    "        run = p.add_run(\"Exploratory data analysis, der ledte til data visualization med Power BI, Python eller R. Dertil udbygges i første omgang en række excel ark, som anvendtes af ledelsen til at skabe et økonomisk overblik.\")\n",
    "\n",
    "        p = doc.add_paragraph()\n",
    "        FORMP(p,bodys)\n",
    "        p.alignment = 0\n",
    "        p.paragraph_format.space_before = 2\n",
    "        run = p.add_run(\"Dataanalyse med SAS/VBA på tidsregistreringer\")\n",
    "        p = doc.add_paragraph()\n",
    "        FORMP(p,style)\n",
    "        p.alignment = 0\n",
    "        run = p.add_run(\"Exploratory data analysis og KPI præsentation\")\n",
    "        run.font.italic = True\n",
    "        p = doc.add_paragraph()\n",
    "        FORMP(p,style)\n",
    "        p.alignment = 0\n",
    "        run = p.add_run(\"Exploratory data analysis, som endte med udviklingen af en rutinemæssig og automatisk SAS procedure, til at danne og udgive en række KPI'er, resultatet danner et excel ark, som kan bruges til ledelsesinformation.\")\n",
    "\n",
    "\n",
    "    if \"analyst\" in sub or \"ai\" in decis1  or \"quant\" in sub or \"all\" in sub:\n",
    "        p = doc.add_paragraph()\n",
    "        FORMP(p,bodys)\n",
    "        p.alignment = 0\n",
    "        p.paragraph_format.space_before = 2\n",
    "        run = p.add_run(\"Forskellige python programmer\")\n",
    "        p = doc.add_paragraph()\n",
    "        FORMP(p,style)\n",
    "        p.alignment = 0\n",
    "        run = p.add_run(\"Galakse simulationer og automatisk CV\")\n",
    "        run.font.italic = True\n",
    "        p = doc.add_paragraph()\n",
    "        FORMP(p,style)\n",
    "        p.alignment = 0\n",
    "        run = p.add_run(\"• Når jeg har tid til overs, så kan jeg godt lide at bruge en smule af det på at udvikle Galakse simulationer i Python\\n• For let at kunne søge store mængder af stillinger samtidigt(og kunne ignorere at jeg altid for afslag), Så har jeg udviklet en python code der både danner et CV og en ansøgning. Med basis i mine forrige CV og jobansøgninger. Koden gennemgår en liste af kendte keywords og kompetencer for at kunne finde hvilke der passer bedst på jobopslaget og på min profil. Herefter omdanner koden dele af mit CV og ansøgning for at tilpasse den bedst til stillingen.\")\n",
    "\n",
    "\n",
    "doc.save(\"autoCV.docx\")  \n",
    "\n",
    "# Create a document\n",
    "from docx.dml.color import ColorFormat\n",
    "from docx.shared import RGBColor\n",
    "from datetime import date\n",
    "doc = docx.Document()\n",
    "\n",
    "style = doc.styles['Normal']\n",
    "font = style.font\n",
    "font.name = 'Cambria Math'\n",
    "font.size = Pt(11)\n",
    "bodys = doc.styles['Body Text']\n",
    "font = bodys.font\n",
    "font.name = 'Cambria Math'\n",
    "font.size = Pt(18)\n",
    "font.bold = True\n",
    "\n",
    "\n",
    "titler = doc.styles['Heading 1']\n",
    "font = titler.font\n",
    "font.name = 'Cambria Math'\n",
    "font.size = Pt(18)\n",
    "font.bold = True\n",
    "font.color.rgb = RGBColor(0, 0, 0)\n",
    "\n",
    "spacings = [0,0,0,1] \n",
    "\n",
    "#p_space = p.paragraph_format.line_spacing = 1\n",
    "dag = str(date.today())\n",
    "if Lang == \"English\":\n",
    "\n",
    "    #footer\n",
    "    footer(\"This CV and application was written automatically with Python\")\n",
    "    #big title\n",
    "    tekster(navn, bodys, spacings, False)\n",
    "    tekster(info, style, spacings, False)\n",
    "    \n",
    "    p = doc.add_paragraph();p.alignment = 0\n",
    "    run = p.add_run(dag);\n",
    "    \n",
    "    doc.add_paragraph();\n",
    "    \n",
    "    p = doc.add_paragraph();p.alignment = 0      \n",
    "    if len(compani)>0 and (len(navne)>0):\n",
    "        intr = str(\"Dear \"+navne[0]+\" and \"+compani+\".\")\n",
    "    elif len(compani)>0 and (len(navne2)>0):\n",
    "        intr = str(\"Dear \"+navne2[0]+\" and \"+compani+\".\")\n",
    "    elif len(compani)>0 and not navne and not navne2:\n",
    "        intr = str(\"Dear \"+compani+\".\")\n",
    "    else:\n",
    "        intr = str(\"To whom it may concern.\")\n",
    "    run = p.add_run(intr);\n",
    "    \n",
    "    p = doc.add_paragraph();p.alignment = 0\n",
    "    if not role:\n",
    "        tekstfyld = str(\"I am writing to express my keen interest in the \"+rolle+\" position at \"+compani+\", as advertised on \"+website+\". I am excited about the opportunity to contribute to the growth and success of your organization.\")\n",
    "    elif len(role)>0:\n",
    "        tekstfyld = str(\"I am writing to express my keen interest in the \"+role[0]+\" position at \"+compani+\", as advertised on \"+website+\". I am excited about the opportunity to contribute to the growth and success of your organization.\")\n",
    "    \n",
    "    run = p.add_run(tekstfyld)\n",
    "    \n",
    "    #hardskills\n",
    "    p = doc.add_paragraph();p.alignment = 0\n",
    "    if not role:\n",
    "        run = p.add_run(str(\"I believe I would be an asset to the team and contribute to \"+compani+\"'s continued succes. With my \"+hard[1]+\" skills and knowledge of \"+hard[2]+\" I would make a well-suited candidate for the position. My work at Statistics Denmark has helped me build a strong foundation for data analysis and programming. My coursework has helped me build a strong understanding of mathematics, finance and analysis. My extracurricular projects have helped me gain experience with programming in Python and R for insurance and quantitative finance.\"))\n",
    "    else:\n",
    "        run = p.add_run(str(\"I believe I would be an asset to the team and contribute to \"+compani+\"'s continued succes. With my \"+hard[1]+\" skills and knowledge of \"+hard[2]+\" I would make a well-suited candidate for the position. My work at Statistics Denmark has helped me build a strong foundation for data analysis and programming. My coursework has helped me build a strong understanding of mathematics, finance and analysis. My extracurricular projects have helped me gain experience with programming in Python and R for insurance and quantitative finance.\"))\n",
    "    \n",
    "    \n",
    "    #softskills\n",
    "    p = doc.add_paragraph();p.alignment = 0\n",
    "    run = p.add_run(str(\"In addition to my technical skills, I possess several soft skills that align well with the requirements of this position. I am a \"+soft[1]+\" and \"+soft[2]+\" individual, always seeking to learn more and improve my abilities. My strong collaborative skills allow me to work well with others, and I thrive in a flexible and varied work environment. I am confident that these qualities will contribute to the success of \"+compani+\".\"))\n",
    "    \n",
    "    p = doc.add_paragraph();p.alignment = 0\n",
    "    run = p.add_run(str(\" The opportunity to join \"+compani+\" excites me, as it offers a great chance to gain invaluable experience. I am confident that my strong work ethic, curiosity, and dedication to continuous learning will enable me to excel in this position. \"+compani+\"'s reputation, combined with its focus on talent development, aligns perfectly with my career goals and aspirations. I am excited about the possibility of joining \"+compani+\" and becoming part of a dedicated and enthusiastic team.\"))\n",
    "    \n",
    "    #contact me\n",
    "    p = doc.add_paragraph();p.alignment = 0\n",
    "    run = p.add_run(\"I have attached my resume for your review, and I would welcome any opportunity to further discuss how my skills and experience align with the needs of your team. If my application has caught your interest, please feel free to reach out to me via. My website www.mdbrezina.com, e-mail mark@brezina.dk or by giving me a call [+45]31772722. I am available for interviews at your convenience.\");\n",
    "    #best regards\n",
    "    p = doc.add_paragraph();p.alignment = 0\n",
    "    run = p.add_run(\"Sincerely\\nMark Brezina\");\n",
    "    \n",
    "    \n",
    "    \n",
    "elif Lang == \"Dansk\":\n",
    "        \n",
    "        #footer\n",
    "    footer(\"Dette CV og jobansøgning er skrevet automatisk med Python\")\n",
    "    #big title\n",
    "    tekster(navn, bodys, spacings, False)\n",
    "    tekster(info, style, spacings, False)\n",
    "    \n",
    "    p = doc.add_paragraph();p.alignment = 0\n",
    "    run = p.add_run(dag);\n",
    "    \n",
    "    doc.add_paragraph();\n",
    "    \n",
    "    p = doc.add_paragraph();p.alignment = 0      \n",
    "    if len(compani)>0 and (len(navne)>0):\n",
    "        intr = str(\"Kære \"+navne[0]+\" og \"+compani+\".\")\n",
    "    elif len(compani)>0 and (len(navne2)>0):\n",
    "        intr = str(\"Kære \"+navne2[0]+\" og \"+compani+\".\")\n",
    "    elif len(compani)>0 and not navne and not navne2:\n",
    "        intr = str(\"Kære \"+compani+\".\")\n",
    "    else:\n",
    "        intr = str(\"Til læseren af denne ansøgning.\")\n",
    "    run = p.add_run(intr);\n",
    "    \n",
    "    p = doc.add_paragraph();p.alignment = 0\n",
    "    tekstfyld = str(\"Jeg skriver for at vise min interesse i \"+rolle+\" stillingen hos \"+compani+\". Jeg fandt stillingen på \"+website+\". Jeg søger stillingen, da jeg har en interesse i at finde en fuldtidsstilling, hvor jeg kan bruge mine evner indenfor\"+hard[1]+\"og \"+hard[2]+\", og jeg mener, at mine færdigheder og ambitioner passer godt til denne rolle.\")\n",
    "    \n",
    "    run = p.add_run(tekstfyld)\n",
    "    \n",
    "    #hardskills\n",
    "    p = doc.add_paragraph();p.alignment = 0\n",
    "    run = p.add_run(str(\"Jeg ved at jeg vil blive en værdifuld kollega på jeres hold. Ud fra mine nuværende erfaringer i andre stillinger har jeg gode evner mht.\"+hard[1]+\"og \"+hard[2]+\". Min passion for matematik, kodning og udvikling af brugerflader gør mig ideel i stillingen hos \"+compani+\". Jeg er motiveret af at kombinere mine faglige kompetencer med erfaring fra at arbejde i en finansiel institution. Jeg mener selv at jeg opfylder jeres ønsker og krav til kandidaten:\"))\n",
    "    run = p.add_run(str(\"Jeg nyder at løse opgaver i samarbejde med andre og trives i et teammiljø.\\nJeg er \"+soft[1]+\" og \"+soft[2]+\".\\nJeg har en analytisk tilgang til problemløsning og finder det spændende at arbejde med kvantitative metoder.\\nJeg har erfaring med \"+hard[1]+\" og jeg er fortrolig med \"+hard[3]+\".\\nJeg er nysgerrig og motiveret af at lære nyt, og jeg er ikke bange for at bede om hjælp, når det er nødvendigt.\\nJeg ser frem til at bidrage til \"+hard[3]+\". Jeg er også ivrig efter at lære og udvikle mig i en afvekslende hverdag og have mulighed for at samarbejde med mange forskellige kollegaer\\n\"))\n",
    "\n",
    "    #softskills\n",
    "    p = doc.add_paragraph();p.alignment = 0\n",
    "    run = p.add_run(str(\"Jeg gør altid mit bedste for at lære og udvikle mig bedst i stillingen. Mine holdspiller evner gør at jeg arbejder godt sammen med andre, og jeg trives med fleksibilitet og mange foreskellige opgaver. Jeg er sikker på at disse kompetencer kommer til at bidrage til \"+compani+\" ’s succes.\"))\n",
    "    \n",
    "    p = doc.add_paragraph();p.alignment = 0\n",
    "    run = p.add_run(str(\"Jeg har stor interesse for \"+compani+\" strategiske mål og jeg er motiveret af at løfte mig som en del af jeres team og bidrage til jeres fortsatte succes. Jeg vil gerne takke jer for at overveje min ansøgning. Jeg er tilgængelig til at arbejde 15-20 timer om ugen og kan starte snarest muligt.\"))\n",
    "    #contact me\n",
    "    p = doc.add_paragraph();p.alignment = 0\n",
    "    run = p.add_run(\"Jeg har vedhæftet mit CV, og jeg ser frem til at få muligheden for at diskutere mine kvalifikationer og motivation yderligere i en samtale.Jeg håber at jeg har vakt jeres interesse med mit CV og min ansøgning, I er altid velkomne til at kontakt mig, enten via. Min hjemmeside www.mdbrezina.com, email mark@brezina.dk eller ved at ringe til mig på min telefon [+45]31772722.\")\n",
    "    p = doc.add_paragraph();p.alignment = 0\n",
    "    run = p.add_run(\"Bedste hilsner\\nMark Brezina\");\n",
    "    \n",
    "    \n",
    "doc.save(\"autoCL.docx\")  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
